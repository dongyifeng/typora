[TOC]



# 相亲



# 决策树



## 算法框架



## 划分选择

### 信息增益

**信息熵（information enthropy）**

集合D中第 k 类样本的占比 $p_k$

$Ent(D) = -\sum_{k=1}^{|y|}{p_k log_2 p_k}$

$Ent(D) $ 的值越小，D 的纯度越高。



**信息增益**

$Gain(D,a) = Ent(D) - \sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D)$

$\frac{|D^v|}{|D|}$ 加权：每个分支数量不一样。

<font color=red>**信息增益特点：对可取值数目较多的属性有偏好。**</font>



### 增益率

为了克服信息增益：对可取值数目较多的属性有偏好。使用增益率。

Gain_ratio(D,a) = $\frac{Gain(D,a)}{IV(a)}$

$IV(a) = -sum_{v=1}{V}{\frac{|D^v|}{|D|}log{\frac{|D^v|}{|D|}}}$  模仿信息熵。

<font color=red>**增益率特点：对可取值数目较少的属性有偏好。**</font>

### 基尼系数

$Gini(D) =\sum_{k=1}^{|y|}{\sum_{k!=k'}{p_k*p_k'}}$

$= 1 - \sum_{k=1}^{|y|}{p_k^2}$

 

## 剪枝

### 预剪枝

### 后剪枝



## 缺失值处理



# 多变量决策树

