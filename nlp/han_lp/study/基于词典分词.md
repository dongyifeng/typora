[TOC]

# 切分算法

1. 完全切分
2. 正向最长匹配
3. 逆向最长匹配
4. 双向最长匹配

## 完全切分

时间复杂度：O(n^2)

```python
def full_segment(text, dic):
    word_list = []
    for i in range(len(text)):
        for j in range(i + 1, len(text) + 1):
            word = text[i:j]
            if word in dic:
                word_list.append(word)
    return word_list

text = "商品和服务"
dic = {"商品", "服务"}
print(full_segment(text, dic))
// ['商品', '服务']
```

## 正向最长匹配

时间复杂度：O(n^2)

假设：单词越长表达的意义越丰富，所以单词越长优先级越高。

```python
def forward_segment(text, dic):
    word_list = []
    i = 0
    while i < len(text):
        longest_word = text[i]
        for j in range(i + 1, len(text) + 1):
            word = text[i:j]
            if word in dic:
                if len(word) > len(longest_word):
                    longest_word = word
        word_list.append(longest_word)
        i += len(longest_word)
    return word_list


text = "就读北京大学"
dic = {"就读", "北京", "大学", "北京大学"}
print(forward_segment(text, dic))
# ['就读', '北京大学']

text = "研究生命起源"
dic = {"研究", "生命", "起源", "研究生"}
print(forward_segment(text, dic))
# ['研究生', '命', '起源']
```

## 逆向最长匹配

时间复杂度：O(n^2)

与正向最长匹配相反，从文本最后开发向前匹配。

```python
def backward_segment(text, dic):
    word_list = []
    i = len(text) - 1
    while i >= 0:
        longest_word = text[i]
        for j in range(i):
            word = text[j:i + 1]
            if word in dic:
                if len(word) > len(longest_word):
                    longest_word = word
        word_list.insert(0, longest_word)
        i -= len(longest_word)
    return word_list


text = "研究生命起源"
dic = {"研究", "生命", "起源", "研究生"}
print(backward_segment(text, dic))
# ['研究', '生命', '起源']
```

## 双向最长匹配

时间复杂度：O(n^2)

融合了：正向最长匹配，逆向最长匹配。根据一定规则，选出比较好的结果。

规则：

1. 同时执行正向最长匹配和逆向最长匹配，返回词数较少的分词结果。
2. 如果词数相等，返回单字更少的结果。
3. 如果单字也相等，返回逆向最长匹配的结果。

```python
from my_hanlp.forward_segment import forward_segment
from my_hanlp.backward_segment import backward_segment

def count_single_char(word_list):
    return sum(1 for word in word_list if len(word) == 1)

def bidirectional_segment(text, dic):
    f = forward_segment(text, dic)
    b = backward_segment(text, dic)

    if len(f) < len(b):
        return f
    if len(f) > len(b):
        return b
    if count_single_char(f) < count_single_char(b):
        return f
    return b
```

## 效果评测

| 序号 | 原文                 | 正向最长匹配                     | 逆向最长匹配                       | 双向最长匹配                       |
| ---- | -------------------- | -------------------------------- | ---------------------------------- | ---------------------------------- |
| 1    | 项目的研究           | **[项目， 的，研究]**            | [项，目的，研究]                   | [项，目的，研究]                   |
| 2    | 商品和服务           | [商品， 和服，务]                | **[商品， 和，服务]**              | **[商品， 和，服务]**              |
| 3    | 研究生命起源         | [研究生，命，起源]               | **[研究，生命，起源]**             | **[研究，生命，起源]**             |
| 4    | 当下雨天地面积水     | [当下，雨天，地面，积水]         | **[当，下雨天，地面，积水]**       | [当下，雨天，地面，积水]           |
| 5    | 结婚的和尚未结婚的   | [结婚，的，和尚，未，结婚，的]   | **[结婚，的，和，尚未，结婚，的]** | **[结婚，的，和，尚未，结婚，的]** |
| 6    | 欢迎新老师生前来就餐 | [欢迎，新，老师，生前，来，就餐] | [欢，迎新，老，师生，前来，就餐]   | [欢，迎新，老，师生，前来，就餐]   |

正向最长匹配正确率：$\frac{1}{6}$

逆向最长匹配正确率：$\frac{4}{6}$

双向最长匹配正确率：$\frac{3}{6}$

双向最长匹配：在 case_1 和 case_4 上反而选择更差的结果返回了。

规则集的维护：有时就是拆东墙补西墙，有时是帮倒忙。



词典分词核心价值：在于速度，不在于精度。

# 优化匹配

匹配算法的瓶颈之一：判断一个字符串是否存在一个集合（词典）中。

如果用有序集合 TreeMap的话，时间复杂度为O(log n)，n  = len(dic)

如果用散列表（HashMap）的话，时间复杂度O(1) ，但是空间复杂度却上去了。



字典树应运而生。



