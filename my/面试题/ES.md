[TOC]

# 你的ES 是怎么理解的？

1. ES 是建立在全文搜索引擎库 Lucene 基础之上的一个开源的搜索引擎。 
2. ES 是分布式存储的，并且检索速度快。因此 ES 经常被用在网站搜索，公司内部日志的收集和检索。去快速查询服务器日志和记录，去定位问题。

ES 支持：PB 级别数据的秒查。

特点：

- 分布式、高性能、高可用、易扩展、易维护

使用场景：

- 海量数据的全文检索：搜索引擎、垂直搜索、站内搜索
- 数据分析和聚合
- 日志系统
- 特征存储



# Mapping 是什么？你知道 ES 哪些数据类型

ES 中的 Mapping 优点类似数据库中 的“表结构”。Mapping 是定义索引的结构，包含字段名称、字段类型、字段使用的分词器、是否评分、是否创建索引等等。 

**常见数据类型：**

- String 类型
  - text：可分词
  - keyword：不可分词，数据会作为完整字段进行匹配
- Numerica：数值型
  - 基本数据类型：long、integer、short、byte、double、float、half_float
  - 浮点的高精度类型：sacled_float
- Date：日期类型
- Array：数组类型
- Object：对象
- 二进制类型
- 范围类型
- 嵌套类型
- 地理类型
- IP 类型
- Join 类型
- ...



# 倒排索引是什么？

>  面试官：想了解你对基础概念的认知。

传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。

而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。有了倒排索引，就能实现 o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。





倒排索引的结构

倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。

Lucene4+ 开始大量使用数据结构：FST（Finite State Transducer）

FST 优点：

1. 空间占用小，通过对字典中单词前缀和后缀的重复利用，压缩存储空间。
2. 查询速度快。时间复杂度： O(len(str))



Posting list 使用的压缩算法：（高效压缩、快速的编码解码）

- FOR（Frame Of Reference）：针对<font color=red>稠密</font>数组压缩 
  - 核心思想：用<font color=red>减法</font>来削减数值大小，从而达到降低空间存储。
-  RBM（Roaring Bit Map）：针对<font color=red>稀疏</font>数组压缩
  - 解决 FOR 算法缺陷：如果减法的结果差值，依然很大。
  - 核心思想：通过<font color=red>除法</font>来缩减数值大小，但是并不是直接的相除。
  - 







| term index | term dictionary | Posting list | 标记匹配 |
| ---------- | --------------- | ------------ | -------- |
|            | 小米            | 1,2,4        |          |
|            | 手机            | 1,2,3        |          |
|            | NFC             | 4,5          |          |



# 分片数

- 一个分片不超过 32 G
- 节点数 <= 主分片数 * （副本数 + 1）

 

# 详细描述一下 Elasticsearch 索引文档的过程。

协调节点默认使用文档 ID 参与计算（也支持通过 routing），以便为路由提供合适的分片。
shard = hash(document_id) % (num_of_primary_shards)

1. 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 MemoryBuffer，然后定时（默认是每隔 1 秒或者 buffer 写满，默认是堆内存的 10%，最小 48M）写入到 Filesystem Cache，这个从 MomeryBuffer 到 Filesystem Cache 的过程就叫做 refresh（refresh 是在  JVM 中，消耗 JVM 性能，从性能上来说，越少越好）；
2. 当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失，ES 是通过 translog 的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中 ，当 Filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；
3. 在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段（段合并），段的 fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。
4. flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）时；

<img src="/Users/dadao1/dadao/git/typora/images/es/WX20230302-113652@2x.png" style="zoom:33%;" />





# 写优化

针对搜索要求不高，但是对写入要求较高的场景（日志收集）

- 调整 Bulk 线程池和队列
- 加大 Translog Flush 的时间间隔，目的是降低 Iops、Writeblock
- 增加 Index Refresh 间隔，目的是减少 Segment Merge 的次数
- 增加 Buffer 大小，本质也是减少 refresh 的时间间隔，因为导致 segment 文件创建的原因不仅有时间间隔，还有 buffer 空间的大小，写满了也会创建。默认最小值 48M < 堆空间的 10%（默认）< 默认最大限制
- 大批量的数据写入时，尽量控制在低检索请求的时间段，大批量的写入请求越集中越好。
  - 第一是减小读写之间的资源抢占，读写分离
  - 当检索请求数量很少时，可以减少甚至完全删除副本分片，关闭 segment 的自动创建以达到高效利用内存的目的，因为副本的存在会导致主从之间频繁的数据同步，大大增加服务器资源的占用。

- Lucene 的数据的 fsync 是发生在 OS cache ，所以要给 OS cache 预留足够的内存大小。
- 优化节点间的任务分布，尽量在同一个机房中。
- 通用最小化算法，能用更小的字段类型就用更小的，keyword 类型比 int 更快。
- Ignore_above：字段保留的长度，越小越好。（ 太长的字段存入 ES，会根据 ignore_above 的值，进行截断 ）
- 调整 _source 字段，通过 include 和 exclude 过滤，查询的字段越少越好，过滤不必要的字段。
- store：开辟另一块存储空间，可以节省带宽。 
- 禁用 all 字段：all 字段包含所有字段分词后的 Term，作用是可以在搜索时不指定特定字段，从所有字段中检索，ES 6.0 之前需要手动关闭。
- 关闭 Norms 字段：计算评分用的，如果确定当前字段不需要评分，设置 false 可以节省大量的磁盘空间，有助于提升性能。常见的比如 filter 和 agg 字段，都可以设为关闭。
- 关闭 index_options（谨慎使用，高端操作）：词设置用于在 index_time 过程中，哪些内容会被添加到倒排索引的文件中，例如：TF、docCount、position、offsets等，减少 option 的选择可以减少在创建索引时的 CPU 占用率，不过在实际场景中很难确定业务是否会用到这些信息，除非是一开始就非常确定用不到，否则不建议删除。
- 优化 Lucene 层的索引建立，目的是降低 CPU 及 IO



ES 提供了 Bulk API 支持批量操作，大量写入任务时，使用 Bulk 来进行批量写入。Bulk 默认设置批量提交的数据量不能超过 100M。单次批量处理的数据大小应从 5MB ~ 15MB 逐渐增加，当性能没有提升时，把这个数据量作为本系统的最大值。



Lucene 在数据新增时，采用了延迟写入的策略，默认情况下，索引的 refresh_interval 为 1 秒。

Lucene 将待写入的数据写到内存中，超过 1 秒就会触发一次 Refresh，然后 Refresh 会把内存中的数据刷新到操作系统文件缓存系统中。

减少副本数量。



SSD 硬盘。





补充：关于 Lucene 的 Segement：

1. Lucene 索引是由多个段组成，段本身是一个功能齐全的倒排索引。
2. 段是不可变的，允许 Lucene 将新的文档增量地添加到索引中，而不用从头重建索引。
3. 对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗CPU 的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。
4. 为了解决这个问题，Elasticsearch 会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。



# 搜索速度优化

- 使用 filter 代替 query：filter 不计算相关度评分。
- 冷热分离的架构设计
- 避免深度分页，避免分片数量过多，es 提供两种解决方案：scroll search 和 search after
- 
- 禁用 swap
- 注意关于 index type 的使用
- 避免使用稀疏数据
- fielddata：搜索是正排索引，doc_value 是正排索引，存储在磁盘。只有在聚合查询时才用到 doc_value，普通搜索只用到倒排索引即可。可以关闭正排索引。
- Enabled：是否穿件倒排索引
- doc_values：正排索引，对于不需要聚合的字段，关闭正排索引可以节省资源，提高查询速度。
- 开启自适应副本选择（ARS），6.1 版本支持，7.0 默认开启。



# 详细描述删除和更新文档的过程

1. 删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更；
2. 磁盘上的每个段都有一个相应的.del 文件。当删除请求发送后，文档并没有真的被删除，而是在.del 文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del 文件中被标记为删除的文档将不会被写入新段。
3. 在新的文档被创建时，Elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del 文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。

ES 是逻辑删除，将删除的数据存放在 .del 文件中。该文档依然能匹配查询，但是会在结果中被过滤掉。当段段合并时，.del 文件的数据不会被写入新段。



# 详细描述一下 Elasticsearch 搜索的过程。

1. 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；
2. 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。
3. 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
4. 接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰 富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
5. 补充：Query Then Fetch 的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch 增加了一个预查询的处理，询问 Term 和 Document frequency，这个评分更准确，但是性能会变差。*





# 在 Elasticsearch 中，是怎么根据一个词找到对应的倒排索引的？

1. Lucene 的索引过程，就是按照全文检索的基本过程，将倒排表写成此文件格式的过程。
2. Lucene 的搜索过程，就是按照此文件格式将索引进去的信息读出来，然后计算每篇文档打分(score)的过程。





# 对于 GC 方面，在使用 Elasticsearch 时要注意什么？

1. 倒排词典的索引需要常驻内存，无法 GC，需要监控 data node 上 segmentmemory 增长趋势。
2. 各类缓存，field cache, filter cache, indexing cache, bulk queue 等等，要设置合理的大小，并且要应该根据最坏的情况来看 heap 是否够用，也就是各类缓存全部占满的时候，还有 heap 空间可以分配给其他任务吗？避免采用 clear cache等“自欺欺人”的方式来释放内存。
3. 避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan & scroll api 来实现。
4. cluster stats 驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过 tribe node 连接。
5. 想知道 heap 够不够，必须结合实际应用场景，并对集群的 heap 使用情况做持续的监控。
6. 根据监控数据理解内存需求，合理配置各类circuit breaker，将内存溢出风险降低到最低。





# 在并发情况下，Elasticsearch 如果保证读写一致？

1. 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
2. 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
3. 对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。



# 如何监控 Elasticsearch 集群状态？

Marvel 让你可以很简单的通过 Kibana 监控 Elasticsearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标。



# 介绍一下你们的个性化搜索方案？

基于word2vec和Elasticsearch实现个性化搜索

1. 基于word2vec、Elasticsearch和自定义的脚本插件，我们就实现了一个个性化的搜索服务，相对于原有的实现，新版的点击率和转化率都有大幅的提升；
2. 基于word2vec的商品向量还有一个可用之处，就是可以用来实现相似商品的推荐；
3. 使用word2vec来实现个性化搜索或个性化推荐是有一定局限性的，因为它只能处理用户点击历史这样的时序数据，而无法全面的去考虑用户偏好，这个还是有很大的改进和提升的空间；



# ES 的节点类型

- Master：候选节点
- data：数据节点
- voting_only：仅投票节点
- Ingest：预处理节点，作用类似 Logstash 中的 Filter
- ml：机器学习节点
- 
- data_content：数据内容节点
- data_hot：热节点
- data_warm：索引不在定期更新，但认可查询
- data_code：冷节点，只读索引
- Remote_cluster_client：候选客户端节点
- Transform：转换节点



# ES 深度翻页？



# 如何进行中文分词？用过哪些分词器？



常见的中文分词器：

- IK 分词
- HanLP
- 结巴分词
- 清华大学THULAC
- 中科院计算所NLPIR





# 工作中都有哪些场景使用了 ES？

- 搜索业务：
  - 场景：帖子搜索、股票搜索、用户搜索、基金搜索等等。
  - 此场景的特点
    - 高性能：10W QPS，10ms 级别平均响应。
    - 强相关：搜索结果高度匹配用户意图。
    - 高可用：可用性达9999，跨机房容灾。
- 日志实时分析：
  - 场景：系统状态日志：服务质量。业务状态日志：运行分析。用户行为日志：用户画像分析、操作审计。
  - 场景特点：  
    - 时效性：从日志产生到可访问，10秒级或者1分钟
    - 高性能：万亿级日志，秒级响应
    - 灵活性：接口易用灵活，类搜索引擎。
- 特征存储：

