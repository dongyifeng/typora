---
typora-root-url: ../../../typora
---

[TOC]



面试官您好，我叫董一峰，来自河南安阳，我上一家公司是雪球财经，在公司我担任资深 Java 工程师的工作。主要负责搜索系统的架构和研发，了解搜索系统整体架构和流程，像索引系统的流程：获取数据、分析数据、索引入库。搜索引擎的流程：召回、粗排、获取特征、模型排序、重排序、数据组装。对搜索帖子、搜索股票、搜索用户等业务有深入了解。最近几年做的最有价值的项目是“雪球搜索关键字智能提示系统”，我们内部叫这个项目为 sug 服务，这个系统的架构是这样的，将股票信息、用户信息还有热门 Query 的数据进行处理，构建一颗前缀树，进行前缀搜索。前缀树是存放在内存中，即便在单台服务：QPS 为 130 多时，sug 服务的 P99 耗时还在 1ms 以内。我不断优化 sug 服务，**在搜索效果方面**：使用了逻辑回归模型，对检索结果进行智能排序。模型上线后，sug 第一位数据点击率相对提升 35%，提升效果非常好。**在性能方面**：对股票数据、基金数据、用户数据、热门 Query 数据采用异步多路召回，以提高服务性能。**在服务稳定性方面**：我还创新性地设计出了加权前缀树，在前缀搜索时进行剪枝，避免了不必要的检索路径。**数据完整性方面**：为了保证 sug 服务数据不丢失，我采用类似 Redis 持久化的机制的方式：快照备份 + 增量备份的方式进行数据的持久化以及恢复。不不断地迭代过程中，我抽象出索引数据和业务数据，并将索引数据和业务数据隔离开，从事是 sug 服务业务稳定，我们设计出多级缓存的架构，使用 MQ消息异步更新缓存等等。还有很多优化的点，就在不在这里赘述了。



我们是每个季度，公司都有OKR，下边部门去承接公司 OKR。比如某个季度，我们搜索和算法这边 OKR 是提升帖子搜索的效果。大概方向是：对帖子搜索上模型排序。算法那边负责帖子搜索的效果，搜索工程这边负责，在线服务搭建：切流服务接入，召回的调整，特征工程，模型排序。由于我对算法熟悉，就承接了特征工程和模型排序，这个服务。在线服务，不但功能要完成，还要考虑服务性能。上模型前，帖子搜索的服务接口，P99好像就 300ms 左右了。再上模型排序，这确实是一个挑战。从一开始，我就在考虑性能这一块。经过对 Query 分析，我发现搜索服务80% 的 query 是股票，而 90% query 是通过 sug 点击过来的。这样的场景的特定是：Query 来自sug，是标准化后的 Query。一般的 Query 最大的特点，同一个搜索意图，有多种多样的表述。既然有现上线百分90% 流程来自标准化后，我为什么不做一个预加载系统呢？于是我设计了一个预加载系统，得到了搜索的领导，算法的领导的认同。预加在系统：不但解决模型排序的性能问题。为后续尝试更复杂的模型，跟多的特征，做更多的实验，提供有力的支持。它还可以作为搜索服务兜底系统。比如：ES 挂了，搜素服务无法使用了，但是有了预加载系统，90% 的搜索，都是有数据的。当然在做预加载系统时，也遇到了一些问题，比如怎么支持切流上线？如果实验切流方案改了，导致预加载的数据失效，怎么处理？等等。通过二级缓存得等比较好的解决。这就是我日常工作的开展方式。



前缀树、逻辑回归、异步多路召回、Redis 持久化机制。



# 向面试官提问：

1. 您能讲讲公司的战略规划吗？
2. 如果有幸加入咱们公司，你的我的期望是什么？比如说：需要什么能力？做哪些方向的工作？
3. 搜索团队大概多少人？对着面试的职位大概需要具备什么能力？需要做什么事情？
4. Java 职位：我面试的职位，在公司主要做方面的工作？团队多少人？
5. 咱们这边对这个职位有什么期望吗？或者说这个职位要做哪方面的工作？大概需要一些什么技能？



# 服务架构

在线服务：提供雪球所有的搜索服务：帖子搜索、股票搜索、用户搜索等

离线索引服务：维护 ES 索引：索引的创建，删除，更新，跑批



- 用户访问：APP 和 Web 访问

- Ngnix 集群：反向代理

- 网关层：认证鉴权、黑白名单、限流熔断、负载均衡

- 核心业务层：
  - 调用切流实验：（为了线上做实验用的，命中不同的实验策略）
  - 调用 NLP 服务：对 Query 分析：比如是否包含股票
  - 调用预加载服务：对热门Query进行预加载，如果预加载服务有数据，就不需要召回服务和精排服务了。
  - 调用召回服务：从 ES 中进行多路召回，粗排
  - 调用精排服务：帖子的本地特征生成、调用特征服务、调用打分服务、排序、重排。
  - 调用其他部分的服务：填充数据
  - 返回给 APP 端。
- 服务治理模块
  - 服务注册
  - 服务发现
  - 灰度服务
  - 服务降级
- 外部系统：
  - 股票行情系统
  - 帖子系统
  - 用户中心
  - 等等
- 底层
  - ES 集群、Redis、MySQL、MQ、Kafka、Apollo 配置中心、ELK 云日志等等





离线索引服务：

- MQ 消息处理

  - 进入各个业务的MQ消息，维护索引。

  - 调用业务方服务：补全信息。

  - 调用 NLP 服务：分词、文本分析：关联股票、是否重复贴、是否复盘贴。

  - 业务处理：帖子是否降级等

  - 组装索引结构

  - 写入索引。

  - 通知其他在线服务更新（Sug）。

- 定时任务

- 索引重建跑批。



<img src="/images/sb/9e885ba4-c9d8-4bb3-af8b-2611078e2387.png" style="zoom: 50%;" />







# 为什么使用Trie Tree 而不是 ES？

之前 sug，没有独立的索引：股票、用户、投资组合、群组，并发请求对应的 ES 索引。



满足业务规则：

1. 股票在前，用户在后

2. 退市的放后面

3. 同名时，A股在上面：股票 > 指数 > 基金 > 债券,在品类里面，比如股票品类，A股 > 港股 > 美股

4. 白名单：处理 badcase 

5. 股票分红当天：股票名称会变位 XD....，一天后有会变回来，还有股票会有 ST....,*ST... ，这个时间就更长，在使用临时名期间，XD 或者 ST *ST也是需要搜出来，当股票名称恢复正常后，之前生成的关键词需要清除。

6. 新股上市，新股权重太小的话，曝光度低。需要给一个较大的权重，7天后，需要恢复成正常的权重。

   

   

Trie Tree 完全基于内存，单机就能完成。离线将分支路径已经数据节点已经排好序了，在下探过程中只需 Top 20，不需要获取全部数据，整体排序后再 Top 20。

ES 是有基于内存的 前缀搜索，但是用 DSL 去实现业务，也是挺麻烦的。况且不能定制化开发。自研 Trie Tree，技术难度不大，可以定 制化开发，性能不比 ES 差，经过优化，甚至超过了 ES 的性能。





# 使用 Trie Tree 结构而没有使用双数组？

一般的算法或者数据结构，往往是时间和空间的某种妥协，如果要提高运行效率，往往需要一些额外的内存空间，反之亦然。而Double-Array之于Trie结构，就好像是一种完美的诠释，在实现了<font color=red>对 Trie 结构空间的充分利用的同时，又不牺牲查找速度</font>，那么是不是Double-Array就无懈可击了呢。当然不是。要驾驭这种优美结构的代价，就是实现 Double-Array 的<font color=red>高复杂性</font>，以及在 Double-Array 中插入，修改，删除单条数据的高代价。AOE在论文中详细介绍了Double-Array的<font color=red>增加，变更，删除条目的操作算法</font>，<font color=red>相较于通俗的Trie实现，要复杂的多得多</font>，本文我也仅仅是将自己对 Double-Array 的一点浅显理解写出来而已，实际上 Double-Array 是一个相当复杂的数据结构，他只能在某些应用场合替代普通的Trie结构，以后如果条件允许，我还会将Double-Array的更多细节一一介绍。

还不如使用 FST 数据结构



# 性能优化

1. 集群化部署，通过负载均衡减轻单机压力。
2. 预加载系统，优化特征服务和模型排序性能，支撑更多的特征和更复杂的模型。
3. Redis 的通过 MQ 异步更新。
4. sug 系统的前缀树加权，前缀匹配下探时进行剪枝，从获取全部数据，排序，再取 TopN，改为直接获取 N 条数据返回，大幅提升优化 sug 服务性能。
5. 帖子搜索时，采用异步多路召回。在综合搜索页，股票、用户、基金、私募等模块，也是采用异步多路召回。
6. 构建多级缓存：页面级缓存（只有第一页），召回策缓存。
7. 综合搜索页接口拆分，将最耗时的帖子搜索，单独抽取出来。使综合搜索页加载更快。
8. 对流量进行 削峰填谷 ，通过 MQ 承接流量。
9. 通过 MQ 消息，新建或跟新帖子索引创建，由一个队列改为两个两个队列，预防更新消息阻塞队列，影响新帖索引创建。
10. 池化技术的使用：线程池、数据库连接池、Redis 连接池。



# 高可用

1. 接口层面的超时设置、重试策略和幂等设计。
2. 降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；
3. MQ场景的消息可靠性保证，包括 producer 端的重试机制、broker 侧的持久化、consumer端的ack机制等，<font color=red>业务上将消息持久</font>，对于没有处理成功的消息，定时任务重新执行。
4. 定时任务校验线上服务的正确性。
5. 灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。
6. 监控报警：全方位的监控体系，包括核心接口超时、错误日志报警、消息队列积压报警、个股页新帖流更新缓慢报警。



# 高扩展

1. 微服务拆分：聚合服务、NLP 服务、召回服务、排序服务、预加载服务、sug 服务。
2. 存储层的拆分：从 MySQL 数据从社区数据库中拆出来了。



# 搜索系统特点

业务：

- 自驱：性能、效果
- 产品策略可能是 case by case 解决问题，需要用全盘的眼光看待问题，彻底解决问题。

技术：

- 系统性能压力大：召回 + 粗排 + 特征 + 精排 + 重排（预加系统）
- 接触算法、NLP。
- 内存使用更大，使用更精细（FST 压缩空间）：比如 NLP 服务可能就需要加载此表。

