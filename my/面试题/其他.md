---
typora-root-url: ../../../typora
---

[TOC]

# 接口幂等设计

定义：接口在参数相同的情况下，调用多次与调用一次，对数据的改变是相同的。

比如：支付操作，如果支付接口被调用多次，应该只能扣一次款。



出现多次请求的原因：

由于网络原因，服务端执行成功了，客户端收到了一个网络超时的异常，客户端为了确保本次操作成功，所以发起了一个重试操作。导致同一个接口被重复调用多次。为了保证服务器端接口的幂等性，我们需要再服务端接口处，<font color=red>**去识别当前请求是否是重复请求**</font>，从而不再对数据做变更操作。



<img src="/images/tmp/WX20230312-184213@2x.png" style="zoom:50%;" />



解决方案：

1. 使用数据库的唯一索引的方式实现。（不适合高并发，性能问题）

   1. 创建一个消息表（幂等表），里面有一个消息ID字段（分布式 ID，也可以消息 MD5），设置为唯一索引。

   2. 一旦出现重复消息，就会抛出异常， 我们可以捕获这个异常，从来避免重复对数据变更。

      

2.   可以使用 Redis 中的 setnx 命令（分布式锁）

   1. 将请求中的唯一标识的信息，存储到 Redis 里面，根据 setnx 的返回结果，来判断是否重复执行。

   2. 如果是，则丢弃该请求。

      

3. 可以使用状态机的方式（乐观锁）

   1. 很多业务中都会存在业务状态的流转，并且这个状态的流转只会前进，不会后退。所以对数据进行修改的时候，只需要在条件中带上当前状态，就可以避免数据重复修改。

   

<img src="/images/tmp/WX20230312-194806@2x.png" style="zoom:30%;" />









# 限量流

**限流场景**

1. 突发流量：微博明星出轨
2. 恶意流量：爬虫、恶意攻击



**限流方案**

1. 基于计数的限流器

    比如每分钟处理100次请求，那么在内存中用一个计数器计数，如果到了 100 次，在来请求就抛弃。

   <img src="/images/tmp/WX20230312-211212@2x.png" style="zoom:30%;" />

   特点：

   - 简单直观
   - 不平滑，有毛刺（临界值问题）

   <img src="/images/tmp/WX20230312-211344@2x.png" style="zoom:33%;" />

2. 基于滑动窗口的限流

   1. 将过去的一分钟切分成一个一个小块。假设每块 10 秒。
   2. 以 10 秒为一个独立区间，独立统计10秒内请求数。独立小区间请求数求和就是过去一分钟内全部的请求数了。
   3. 每经过 10秒钟，把整个区间向右移动一格。淘汰旧的一格，生成新的一格。

   <img src="/images/tmp/WX20230312-211421@2x.png" style="zoom:33%;" />

3. 漏桶算法

   1.  类似消息队列的削峰填谷。漏桶算法。一般不会用真实的消息队列来实现。而是通过设定一个消费速率和桶的最大容量，去计算剩余容量。
   2. 木桶的总容量：C
   3. 消费速率：rate
   4. 处理上一个请求的时间戳：at
   5. 在这段时间内处理掉的流量：wb = (now() - at) * rate
   6. 当前桶内剩余的流量（新的在桶内等待的流量：W - wb）：W = max( W - wb, 0 )。有可能为负，消费完毕后，空闲一段时间。
   7. 判断桶内流量如果小于 C，可以执行，否则拒绝。
   8. 从此过程看来，此算法没有真正使用队列，而是通过固定速率，模拟一个桶中流量。所以导致它的消费最大速度是固定的。如果使用真实队列，消费速度就是真实的速度，也是变化的，就和令牌桶一样，具有支持突发流量的功能了。
   9. 消费速度可控、稳定。
   10. 整个系统处理漏桶漏出的稳定的流量，自然就可以达到限流的效果。
   11. 

   <img src="/images/tmp/WX20230312-212041@2x.png" style="zoom:33%;" />

   不支持突发流量。

4. 令牌桶算法

   1. 每一个请求，先从桶中申请令牌，申请到令牌就去处理，否则拒绝。
   2. 如果在一段时间内，请求的速度都是高于令牌放入的速度，令牌桶中很快就没有令牌可用了，服务就会拒绝一部分请求，保证系统处理的流量在我们控制范围内。
   3. 还有一个程序，定时向桶中放令牌：
      1. 比如：每 10 秒钟放 10 个令牌。或者每 60 秒放 60 个令牌。
      2. 如果滑动窗口比：滑动窗口每 10 秒有一批新流量放出来，但是如果10秒内没有流量，这个流量不能积攒，而令牌桶可以积攒流量，最大积攒量是桶的容量。
   4. 支持突发流量

   

   <img src="/images/tmp/WX20230312-212528@2x.png" style="zoom:33%;" />

代码实现：

Guava 包







# 线上问题排查

海恩法则

> 每一起严重事故的背后，必然有 29 次轻微事故和 300 起未遂先兆以及 1000 起事故隐患。



### 线上故障产生原因

任何重大生产事故在发生之前都有迹可循，事故发生并非偶然，归结起来存在个人和团队两方面疏漏：

1. 个人原因：基础不牢靠、自测不充分、做事浮躁、侥幸心理、前瞻性不足（未评估高并发或数据快速增长带来的流量和数据存储和查询压力）等等；
2. 团队原因：没有制定（或没有严格执行）研发流程（比如code review、测试不充分等）来保证质量、赶工期、团队沟通不畅等等；



### 应急目标、流程

当遇到线上事故时，应急目标是：快速恢复服务，减少事故造成的损失，减少事故对客户的影响。

事故处理流程包含以下4步骤：

1. 保留现场：在不影响用户体验前提下，要保留现场和数据；
2. 恢复系统：在初步分析原因下，如果是自身系统的原因可采用回滚策略快速恢复服务、快速止损，如果是外部系统原因则需要及时沟通，了解故障处理进度；
3. 分析事故原因和影响；通过保留的现场分析事故产生的原因和造成的影响；
4. 线上事故回溯：回顾问题和避免措施。



注意，事故处理流程和问题解决流程差异：事故处理强调的是快速恢复，止损；问题解决强调找到产生问题的根源和解决办法。



线上问题分可稳定复现和不能稳定复现两类，对于可稳定复现的问题，从日志堆栈上能直接看出问题；对于不能稳定重现的问题，经验表明一般和多线程有关，解决问题的一般思路是：

1. 通过code review、压测、调整代码来增加多线程问题复现的概率；
2. 利用 Jvm 相关工具分析线程堆栈，内存使用情况，死锁等；
3. 宿主机的负载情况，包含：cpu、磁盘、内存、网络IO等；
4. 能够结合现象说明一定的排错逻辑（不一定非常强，很多时候会猜测）；
5. 事后能提出一些有效的防范措施。



为了缩小问题定位的范围，可以从以下6方面入手：

1. 系统最近是否有上线？
2. 基础平台最近是否有升级？
3. 依赖的系统最近是否进行过上线？
4. 是否是运营误操作导致故障（比如导数功能造成造成内存耗尽）？
5. 是否是网络抖动？
6. 业务是否上量（吞吐量、数据量）、是否有促销等运营手段造成突发的大量请求？



监控数据有利于定位问题，定位问题一般会从：**系统层面、应用进程层面和数据层面** 3个层面的监控数据进行分析定位：

1. 系统层面：系统CPU利用率是否正常、系统负载、内存使用情况、网络I/O负载、磁盘负载、IO等待、交换区使用、线程数、打开的文件句柄；
2. 应用进程层面：接口响应时间（TP99）、吞吐量、调用频次、接口成功率等；
3. 数据层面：数据库负载、慢SQL、数据库连接数；缓存连接数、占用内存、吞吐量、响应时间；消息队列响应时间，吞吐量、负载、积压情况；